{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('concatenated_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_body'] = df['title'] + ' ' + df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Sweet book. Great for Father's Day Bought this...\n",
       "1      One of my favourites Such a lovely book which ...\n",
       "2                                      childs book great\n",
       "3      Great gift for a first time dad. Gave this as ...\n",
       "4      Super cute Love this book bought it for my dau...\n",
       "                             ...                        \n",
       "575    Great read and very relevant as we move furthe...\n",
       "576    Four Stars Good Book, not for light reading th...\n",
       "577                      Five Stars Really Helpful book!\n",
       "578    Many typos in the kindle version Disappointing...\n",
       "579    Too hard to read on paperback Font is small an...\n",
       "Name: title_body, Length: 580, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['title_body'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec\n",
    "import tensorflow_hub as hub\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Universal Sentence Encoder's TF Hub module\n",
    "model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 21:57:59,063 - top2vec - INFO - Pre-processing documents for training\n",
      "INFO:top2vec:Pre-processing documents for training\n",
      "/Users/grahammarsh/Documents/GitHub/project4/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2024-06-05 21:57:59,149 - top2vec - INFO - Creating joint document/word embedding\n",
      "INFO:top2vec:Creating joint document/word embedding\n",
      "2024-06-05 21:57:59,744 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "INFO:top2vec:Creating lower dimension embedding of documents\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "2024-06-05 21:58:04,526 - top2vec - INFO - Finding dense areas of documents\n",
      "INFO:top2vec:Finding dense areas of documents\n",
      "2024-06-05 21:58:04,542 - top2vec - INFO - Finding topics\n",
      "INFO:top2vec:Finding topics\n"
     ]
    }
   ],
   "source": [
    "model2 = Top2Vec(docs, embedding_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[501  79]\n"
     ]
    }
   ],
   "source": [
    "topic_sizes, topic_nums = model2.get_topic_sizes()\n",
    "print(topic_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(topic_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_nums = model2.get_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['book' 'books' 'loved' 'reading' 'read' 'amazing' 'great' 'recommend'\n",
      " 'good' 'series' 'author' 'best' 'story' 'much' 'love' 'very' 'really'\n",
      " 'first' 'one' 'this' 'little' 'written' 'way' 'an' 'characters' 'such'\n",
      " 'have' 'had' 'has' 'like' 'into' 'well' 'not' 'it' 'about' 'with' 'get'\n",
      " 'that' 'who' 'no' 'been' 'the' 'many' 'some' 'would' 'as' 'her' 'through'\n",
      " 'end' 'so']\n",
      "1\n",
      "['book' 'reading' 'read' 'books' 'much' 'recommend' 'an' 'she' 'very' 'so'\n",
      " 'have' 'one' 'really' 'great' 'this' 'author' 'about' 'all' 'good' 'has'\n",
      " 'written' 'best' 'such' 'who' 'many' 'for' 'had' 'loved' 'with' 'into'\n",
      " 'know' 'and' 'her' 'now' 'life' 'every' 'not' 'to' 'am' 'by' 'what' 'no'\n",
      " 'as' 'amazing' 'it' 'also' 'get' 'way' 'well' 'from']\n"
     ]
    }
   ],
   "source": [
    "for words, scores, num in zip(topic_words, word_scores, topic_nums):\n",
    "    print(num)\n",
    "    print(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n",
      "A fantastic book. Unbelievably unhinged!! What a fantastic, fantastic book. Had me hooked from the first page. It only took me 3 days to read (not a fast reader usually) I don't think I've ever read a book this quick. I couldn't put it down and when I did I couldn't stop thinking about it. Do yourself a favour and read this book, you won't be disappointed!\n",
      "0.7858136\n",
      "374\n",
      "Could not put this down. This was the first Lisa Jewell book I have read - and what an introduction it was! This book was one of the best books I have read all year, full of emotion, twists and turns and the characters were such a fascinating read. Would recommend this for those who love a good thriller. Will be reading more from this author.\n",
      "0.7671149\n",
      "401\n",
      "A brilliant read I loved this book. Lots of fwists and turns. The ending was brilliant. I couldn't put it down .\n",
      "0.7666582\n",
      "380\n",
      "AMAZING!!! Just finished this book, and as a first time Lisa Jewell reader, I can safely say that I am now a huge fan. This book is an amazing psychological thriller, with so many twists and turns right until the end. Already looking for more of this authors book to read!\n",
      "0.7661654\n",
      "405\n",
      "Brilliant book - couldn't put it down Once I started this book I was gripped. It really was intense with lots of twists and turns. I would definitely recommend\n",
      "0.7657405\n",
      "452\n",
      "Great read I really enjoyed this book , finished it in a day. Loved the characters and the family in which you could relate too. Can't wait to read the series.\n",
      "0.7583383\n",
      "34\n",
      "Fantastic!! I absolutely loved this book!! Could never have guessed how it would end but it has kept me thinking long after I finished the book!! Its a must read!!\n",
      "0.7543168\n",
      "371\n",
      "Another chance I have to admit I have read a few of Lisa Jewell’s books before. Unfortunately the last couple that I read just wasn’t for me so when this came out I didn’t rush out to by it but after seeing so many positive reviews I thought I would give her another chance and wow I’m so glad I did!! This book was brilliant. It kept me entertained and hooked from the beginning. The ending left me wanting more. Based on THIS book I am definitely going to read more books from Lisa Jewell. Definitely recommend this 4 star read!!\n",
      "0.7507144\n",
      "521\n",
      "just finished this - going to have the biggest book hangover Ok wow.  This is a must read for anyone who ever has been or will be in a romantic relationship. It's one of those rare books with an important message that is still enjoyable to read. It was hard in moments, definitely, but I also laughed and loved along with the characters.  I didn't read any reviews or the blurb - I loved 'slammed' and 'November 9' so as soon as I saw it was Colleen Hoover I was in. So I had no idea what to expect - which I think is the perfect way to experience this book. To go on the journey with the character. To fall in love with the characters without the preconceptions of knowing what will happen further on.  So no spoilers from me. Read this book, it is brave and bold, it is dark and funny at times, sweet and romantic at others, and bitter and hopeful all at the same time.\n",
      "0.7462563\n",
      "511\n",
      "Fair warning: This book will make you cry! I have loved every Colleen Hoover book I have read and this one did not disappoint. My neighbour recommended I read Colleens latest book and as I was in a bit of a book slump I decided to give it a go. It'd been a year or more since I picked up one of her books and I will be reading and rereading her books over the next week. I devoured this story in 5-6 hours and could not put it down. I laughed and cried and I cried some more. Lilly and Ryle are such fabulous characters and I hurt for both of them. I can only imagine how hard it would be to write a story centering around domestic violence and to do it so well, but Colleen has done such an amazing job. Congratulations on such a wonderful book, I look forward to reading more.\n",
      "0.7453353\n"
     ]
    }
   ],
   "source": [
    "documents, document_scores, document_ids = model2.search_documents_by_topic(topic_num=0, num_docs=10)\n",
    "\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(doc_id)\n",
    "    print(doc)\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
